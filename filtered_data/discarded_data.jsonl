{"Paper Title": "Mechanical performance of steel-polypropylene hybrid fiber reinforced concrete subject to uniaxial constant-amplitude cyclic compression: Fatigue behavior and unified fatigue equation", "Abstract": "In the natural environment, concrete-built structures are frequently undergoing repetitive loadings, e.g., earthquake, automobile traffic, or wind during their entire service life. Those repetitive cyclic loadings trigger gradual initiation, expansion and coalesce of inner cracks, resulting in progressive deterioration of mechanical performance until eventual fatigue failure. This paper presents a hybrid fiber reinforcing strategy that could significantly increase the service life of concrete. In this work, the compressive fatigue performance of steel-polypropylene hybrid fiber reinforced concrete (HFRC) under fatigue compression was investigated. A total of 36 groups of prismatic specimens were tested for various stress levels (0.7, 0.8, and 0.9). With respect to the fatigue deformation, fatigue life, and fatigue strength, the effects of fiber parameters were analyzed, including steel fiber volume fractions (1%, 1.5%, and 2%) and aspect ratios (30, 60, and 80), as well as polypropylene fiber volume fractions (0.1%, 0.15%, and 0.2%) and aspect ratios (167, 280, and 396). The results showed that the incorporation of hybrid fiber exerts a pronounced impact on the fatigue performance of concrete. Specifically, in contrast to plain concrete, the ultimate fatigue deformation and fatigue strength of HFRC could be increased by up to 63.29% and 37.18%, respectively. In addition, owing to a positive synergetic effect generated in the hybrid system, HFRC is more superior to polypropylene fiber reinforced concrete (PFRC) or steel fiber reinforced concrete (SFRC) in fatigue performance. Furthermore, a unified fatigue model was proposed to estimate the fatigue strength of HFRC with consideration of fiber parameters. The predictions were found to correlate well with available experimental results, demonstrating a wide applicability of the model in prediction of fatigue life of concrete with reasonable"}
{"Paper Title": "Physics-guided neural network for structural seismic response reconstruction based on floor response spectra", "Abstract": "Structural seismic response monitoring (SSRM) systems typically can only measure responses at limited locations, leading to the incomplete attainment of dynamic responses. This study developed an end-to-end physics-guided neural network with adaptive multi-level fusion outputs. Incorporating the concept of autoencoders, the network reconstructs seismic responses at non-instrumented floors based on base and roof acceleration records, and structural characteristics. The floor response spectra (FRS) are incorporated into the neural network's loss function as a physical constraint to improve prediction accuracy and enhance its physical significance. Finally, the proposed prediction model's performance and generalization ability were validated using numerical data of five reinforced concrete (RC) frame structures with varying characteristics, measured data of an RC frame shaking table test, and monitoring data of an RC frame structure under earthquake. In addition, the predicted accelerations were further applied to evaluate the damage states of non-structural components (NSCs). Results show that, for acceleration time-history prediction, the physics-informed loss function of FRS reduces absolute percentage error (APE) from 24.06 % to 20.37 %, increases cross-correlation coefficient (XR) to 0.7928, and decreases both normalized mean absolute error (NMAE) and normalized mean squared error (NMSE). For FRS prediction, APE is reduced by 3.58 % and XR rises to 0.9450. The damage assessment accuracy for NSCs reaches 76.2 %. These demonstrate that the proposed structural seismic response reconstruction method exhibits excellent predictive performance in numerical, test and monitoring data, and can be effectively applied to NSCs evaluation."}
{"Paper Title": "Damage evaluation of RC framed structure with peripheral oblique columns against progressive collapse through seismic fragility analysis", "Abstract": "Severe conditions such as blast loading and seismic events can seriously damage a structure's performance when a load-bearing member is damaged, resulting in the structure's progressive collapse. The damage assessment caused by the progressive collapse of the Reinforced Concrete (RC) structure with peripheral oblique columns owing to ground-storey column removal was analyzed in this study. The effect of different angles, such as 6°, 8°, and 10° with respect to the vertical of peripheral oblique columns, was evaluated. The non-linear time history analysis was performed by taking past seismic ground motion records. The findings were collected about vertical deflection and chord rotation of the joint above the column removal position. The seismic fragility diagrams used to assess the damage to the structure were derived from Incremental dynamic analysis (IDA) curves. The probability of exceedance of certain performance stages, such as Operation phase (OP), Immediate occupancy (IO), Damaged control (DC), Life Safety (LS), and collapse prevention (CP) was discussed. Results show that structures with oblique columns could control the vertical displacement and chord rotation of the joint. The Demand capacity ratio (DCR) was lower in the models with peripheral oblique columns. Further, findings show that the two-step column removal approach was more realistic than the sudden column elimination. The oblique column structures with 6° of obliquity showed a higher rate of reduction in the Probability of exceedance (POE) of a particular damage state at all Peak ground acceleration (PGA) intensities."}
{"Paper Title": "Physics-informed deep learning model in wind turbine response prediction", "Abstract": "Subjected to strong cyclic wind and wave loads, wind turbines could experience severe fatigue damages and possibly fail to function normally due to accumulated damages at certain critical locations. Therefore, fatigue damage evaluation and prediction are essential and important to be conducted, which could involve massive numerical simulations and computational costs due to dynamic analyses of the wind turbines under various environmental conditions. To reduce the calculation cost related to the time-consuming dynamic analysis, sequence models such as the recurrent neural network (RNN) and the long-short term memory model (LSTM) originated from the deep learning topic are good and promising candidates to predict structural dynamic responses at multiple critical locations under different environmental scenarios. However, the training cost and prediction accuracy of these deep learning models might not be satisfiable since these models are purely data-driven and require significant amount of training data and a large number of training parameters. To reduce the computational cost and improve the prediction accuracy, a hybrid method that integrates the physical information of the underlying wind turbine system into the data-driven model is implemented in the present study as a computationally efficient simulation model. Structural properties and linearized representations of the wind turbine system are served as the physical constraints and applied in a recently proposed deep residual recurrent neural network (DR-RNN) to form as a physics-informed deep learning model. This physics-informed model is first applied to a frame structure with four degrees of freedom as a benchmark study to show the accuracy and efficiency of this model. The applicability of this physics-informed model to a complex wind turbine system is then investigated, and the performance of the developed physics-informed model on the structural response prediction is also compared with a regular data-driven model."}
{"Paper Title": "A general deep learning framework for history-dependent response prediction based on UA-Seq2Seq model", "Abstract": "A general deep learning framework based on the Unrolled Attention Sequence-to-Sequence (UA-Seq2Seq) model is developed to address the history-dependent response prediction problem. First, the particular traits of the history-dependent response prediction problem are analyzed, which motivate the incorporation of the unrolled gated recurrent unit (GRU) structure and the attention mechanism into the classical Seq2Seq model in natural language processing. In the UA-Seq2Seq model, the Seq2Seq skeleton frees the restrictions on both the input and target mechanical variables. Meanwhile, the novel unrolled GRU structure conforms to the general process of mechanical simulation and manages to establish the gated links with the historical states, which is further boosted by the powerful attention mechanism dedicated to retrieving the super-long-term memory information. To quickly and informatively validate the UA-Seq2Seq model, a numerical experiment based on the cyclic stress–strain response of low-yield-point steel is conducted, whose constitutive behavior depends highly on the loading history. All the training and testing configurations in the numerical experiment are specified, including a novel data normalization method – named nonlinear reference-value scaling – tailored for mechanical variables. The results verify the effectiveness of the UA-Seq2Seq model to reproduce the history-dependent hysteresis loops and confirm its capability to capture the long-term memory effect. Furthermore, a parametric analysis is carried out to demonstrate the necessity of the unrolled structure and the attention mechanism as well as the advantage of selecting the L1 loss metric, following which a qualitative mechanical interpretation of the UA-Seq2Seq model is provided to aid in the intuitive comprehension. Finally, three feasible applications and extensions of the developed framework are introduced conceptually: integration with finite element analysis, outline analysis, and transfer learning to other similar tasks. Therefore, the proposed deep learning framework is able to cover a wide range of scenarios concerning the mechanical history-dependent response simulation in practice, which facilitates its universal employment in the academic research and engineering design."}
{"Paper Title": "A novel long short-term memory neural-network-based self-excited force model of limit cycle oscillations of nonlinear flutter for various aerodynamic configurations", "Abstract": "Due to the strong nonlinear properties of the entire flutter process [including growth stages, decay stages and steady limit cycle oscillations (LCOs)], the generalization of the self-excited force model for the entire flutter process of bluff bodies is a very critical issue. This paper proposes a self-excited force model based on a novel long short-term memory (LSTM) neural network to simulate the entire flutter process for various leading-edge configurations. To obtain the dataset, the nonlinear flutter with the growth stages, decay stages and steady LCOs for different leading-edge aerodynamic configurations is investigated by a series of two-degrees-of-freedom spring-suspended sectional model tests. Based on the measured flutter responses and self-excited forces in the tests, a data-driven self-excited force model is proposed on the basis of a novel LSTM neural network. Considering that the nonlinear dynamic system is very sensitive to the accuracy of the model parameters, the Newmark-B method is incorporated into the LSTM networks and forms a closed-loop process to restrain the error amplification effects and improve the model robustness, that is, the response calculated from the output of LSTM (the self-excited force) by the Newmark-B method is set as the input of LSTM at the next step rather than the measured response. To validate the performance of the proposed model, the flutter critical wind speed, time history of oscillation and self-excited forces, steady-state oscillation amplitude and flutter development process predicted by the model are compared with the test results. The comparison indicates that the predicted results agree well with the test results, meaning that the proposed model has high accuracy, generalization and robustness in describing the nonlinear characteristics of the flutter for various aerodynamic configurations."}
{"Paper Title": "Attention-based LSTM (AttLSTM) neural network for Seismic Response Modeling of Bridges", "Abstract": "Accurate prediction of bridge responses plays an essential role in health monitoring and safety assessment of bridges subjected to dynamic loads such as earthquakes. To this end, this paper leverages the recent advances in deep learning and proposes an innovative attention-based recurrent neural network for metamodeling of bridge structures under seismic hazards. The key concept is to establish an attention-based long short-term memory neural network (AttLSTM) to learn the dynamics from limited training data and make predictions of bridge responses against unseen earthquakes. In particular, an attention mechanism is proposed to enhance the selection of more informative components among sequential data for better learning from limited data. The performance of the proposed AttLSTM neural network was validated through both numerical and real-world data of a girder bridge and a cable-stayed bridge to systematically evaluate the prediction performance of the proposed method. In addition, the classical LSTM neural network was selected as the baseline model to show the favorable performance of the proposed attention mechanism. Results indicate that the proposed method with attention mechanism outperforms the compared state-of-the-art LSTM in terms of both accuracy and reliability."}
{"Paper Title": "Recursive long short-term memory network for predicting nonlinear structural seismic response", "Abstract": "Artificial neural networks have been used to predict nonlinear structural time histories under seismic excitation because they have a significantly lower computational cost than the traditional time-step integration method. However, most existing techniques require simplification procedures such as downsampling to maintain identical length and sampling rates, and they lack sufficient accuracy, generality, or interpretability. In this paper, a recursive long short-term memory (LSTM) network was proposed for predicting nonlinear structural seismic responses for arbitrary lengths and sampling rates. Referring to the traditional integral solution method, the proposed LSTM model uses the recursive prediction principle and is therefore applicable to structures and earthquakes with different spectral characteristics and amplitudes. The measured ground motions and multilayer frame structures were used for model training and validation. The rules of hyperparameter selection for practical applications are herein discussed. The results showed that the proposed recursive LSTM model can adequately reproduce the global and local characteristics of the time history responses on four different structural response datasets, exhibiting good accuracy and generalization capability."}
{"Paper Title": "Physics-guided convolutional neural network (PhyCNN) for data-driven seismic response modeling", "Abstract": "Accurate prediction of building’s response subjected to earthquakes makes possible to evaluate building performance. To this end, we leverage the recent advances in deep learning and develop a physics-guided convolutional neural network (PhyCNN) for data-driven structural seismic response modeling. The concept is to train a deep PhyCNN model based on limited seismic input–output datasets (e.g., from simulation or sensing) and physics constraints, and thus establish a surrogate model for structural response prediction. Available physics (e.g., the law of dynamics) can provide constraints to the network outputs, alleviate overfitting issues, reduce the need of big training datasets, and thus improve the robustness of the trained model for more reliable prediction. The surrogate model is then utilized for fragility analysis given certain limit state criteria. In addition, an unsupervised learning algorithm based on K-means clustering is also proposed to partition the datasets to training, validation and prediction categories, so as to maximize the use of limited datasets. The performance of PhyCNN is demonstrated through both numerical and experimental examples. Convincing results illustrate that PhyCNN is capable of accurately predicting building’s seismic response in a data-driven fashion without the need of a physics-based analytical/numerical model. The PhyCNN paradigm also outperforms non-physics-guided neural networks."}
{"Paper Title": "A Multitask Fourier Transformer Network for Seismic Source Characterization Estimation From a Single-Station Waveform", "Abstract": "This study introduces a novel approach for the estimation of seismic source parameters using a multitask learning network that incorporates a Fourier Transformer architecture. The Fourier Transformer is designed to extract information from both the time and frequency domains, which reduces the time complexity by utilizing a fast Fourier transform (FFT) in place of the traditional attention mechanism in the Transformer encoder. The network consists of a shared encoder for general feature extraction and four task-specific decoders for parameter estimation. The model is both lightweight and accurate, capable of simultaneously estimating magnitude, epicentral distance, p travel time, and depth based on a 30-s single-station waveform. The proposed approach was validated using the Stanford Earthquake dataset (STEAD) and compared with the state-of-the-art techniques. The results show standard deviations of 0.19 for magnitude, 3.77 km for epicentral distance, 0.46 s for p travel time, and 5.77 km for depth, with a lower error and a faster response compared to the existing prediction framework. The code is available at https://github.com/KG-TSI-Civil/MFTnet. © 2004-2012 IEEE."}
{"Paper Title": "Improvement of the seismic resilience of regional buildings: A multi-objective prediction model for earthquake early warning", "Abstract": "Earthquake early warning is one of the methods by which to improve structural resilience. However, uniform earthquake warning information is not highly targeted for regional buildings. Therefore, this work proposes a multi-objective earthquake warning process to provide more targeted earthquake avoidance measures for regional buildings. A multi-objective prediction model based on long short-term memory (LSTM) is established. The \"Di Ting\" dataset provided by China's National Earthquake Data Center is currently the largest artificial intelligence seismology training dataset. The proposed model uses 3 s of P-wave data from the dataset to predict the single-station magnitude, epicenter distance, and peak ground acceleration (PGA) of earthquakes. To achieve better predictive performance, the mean squared error (MSE) is redesigned. The average prediction errors of the magnitude and epicenter distance are found to be reduced, and the multi-objective model can achieve good predictive performance and meet the requirements of all the objectives. The predicted magnitude is used to determine whether an earthquake warning should be issued, the epicenter distance is used to determine the response time, and the PGA is used to determine the engineering status of the building. More targeted risk avoidance measures can be chosen for different building based on their disaster situation. The proposed multi-objective warning process can provide more targeted advice on how to avoid risks to buildings and reduce unnecessary panic and casualties. This is a useful attempt to improve the seismic resilience of regional buildings."}
{"Paper Title": "Shape function-based multi-objective optimizations of seismic design of buildings with elastoplastic and self-centering components", "Abstract": "Although the current seismic design of buildings ensures collapse resistance, repairs after disasters are time-consuming and costly. High performance structures and reliable design methods that consider repairability are required for resilient communities. This paper proposes a shape function-based framework and adopts a flexural-shear multi-degree-of-freedom model for seismic design optimization. The proposed framework has fewer parameters and higher portability, and provides better results than a component-based framework. Multi-objective particle swarm optimization is adopted to determine feasible structures for multiple requirements. The optimization provides well-designed elastoplastic and self-centering components of 10–60 floor structures and generates suitable maximum displacement, residual displacement, and cost. A simplified calculation method based on the optimized result is proposed and is verified to guarantee a good performance. Additional optimization of the re-centering ratio and hybrid damping of the self-centering component provides a triangular distribution of the re-centering ratio with values of 1.14–1.26 on the lower floor and a viscous damping ratio of 0.04 to 0.07 for each floor. The maximum acceleration is controlled by 0.8 g after the incorporation of hybrid damping."}
{"Paper Title": "Street view imagery in urban analytics and GIS: A review", "Abstract": "Street view imagery has rapidly ascended as an important data source for geospatial data collection and urban analytics, deriving insights and supporting informed decisions. Such surge has been mainly catalysed by the proliferation of large-scale imagery platforms, advances in computer vision and machine learning, and availability of computing resources. We screened more than 600 recent papers to provide a comprehensive systematic review of the state of the art of how street-level imagery is currently used in studies pertaining to the built environment. The main findings are that: (i) street view imagery is now clearly an entrenched component of urban analytics and GIScience; (ii) most of the research relies on data from Google Street View; and (iii) it is used across myriads of domains with numerous applications – ranging from analysing vegetation and transportation to health and socio-economic studies. A notable trend is crowdsourced street view imagery, facilitated by services such as Mapillary and KartaView, in some cases furthering geographical coverage and temporal granularity, at a permissive licence."}
{"Paper Title": "Automating building element detection for deconstruction planning and material reuse: A case study", "Abstract": "To address the need for a shift from a linear to a circular economy in the built environment, this paper develops a semi-automated assistive process for planning building material deconstruction for reuse using sensing and scanning, Scan-to-BIM, and computer vision techniques. These methods are applied and tested in a real-world case study in Geneva, Switzerland, with a focus on reconstruction and recovery analysis for floor beam systems. First, accessible sensing and scanning tools, such as mobile photography and smartphone-based consumer-grade Lidar devices, are used to capture imagery and other data from an active demolition site. Then, photogrammetry and point cloud data analysis are performed to construct a 3D BIM model of relevant areas. The structural relationships between reconstructed BIM elements are evaluated to score the feasibility for recovery of each element. This study illustrates what is feasible and where further development is necessary for automating building material reuse planning at scale to increase the uptake of circular economy practices in the construction sector."}
{"Paper Title": "Automatic Building Age Prediction from Street View Images", "Abstract": "Building age is a key factor for building energy efficiency, valuation of real estate objects and urban planning, while previous research has been limited by the available building age data and efficient ways to estimate building age information. This paper presents an automated workflow for estimating building age from street view images. A building age dataset consisting of street view images that are labeled with the date of construction is created for Amsterdam. We designed a deep convolutional neural network for the estimation of building age and achieved a total accuracy of 81%. This research utilizes publicly available data, street view images, and construction dates of buildings, to perform the estimation of building age with an automated manner."}
{"Paper Title": "Automated classification of building structures for urban built environment identification using machine learning", "Abstract": "The urban environment, especially buildings with different structure types, is difficult to identify automatically due to variation in urban function and form and to buildings’ relatively tacit structural attributes. To enable automated classification of building structures in complex urban environment, this study developed a machine learning (ML)-based method. Twenty-nine ML features were defined, and twelve popular ML algorithms were tested. The method was tested by classifying over 3700 buildings in Beijing, China into five common structures. Of the 12 ML algorithms, the Gradient Boosted Decision Tree delivered the highest overall performance, and its classification was verified as effective, i.e., achieving approximately 91.7%, 90.6%, and 91.1% of average recall, precision and F1, respectively, on testing data. This study’s classification method helps establish a nexus among urban form, building structures, and materials and resource requirements, thus contributing to the advance of sustainable urban studies, such as urban metabolism and ecological planning."}
{"Paper Title": "Revealing spatio-temporal evolution of urban visual environments with street view imagery", "Abstract": "The visual landscape plays a pivotal role in urban planning and healthy cities. Recent studies of visual evaluation focus on either objective or subjective approach, while describing the visual character holistically and monitor its evolution remains challenging. This study introduces an embedding-driven clustering approach that integrates both physical and perceptual attributes to infer the spatial structure of the visual environment, and investigates its spatio-temporal evolution. Singapore, a highly urbanised yet green city, is selected as a case study. Firstly, a visual feature matrix is derived from street view imagery (SVI). Then, a graph neural network is constructed based on road connections to encode visual features and spatial dependency leading to a clustering algorithm that is used to discover the underlying characteristics of the visual environment. The implementation characterises streetscapes of the city-state into six types of clusters. Finally, taking advantage of historical SVI, a longitudinal analysis reveals how visual clusters have evolved in the past decade. Among them, one of the clusters represents high-density visual experience, affirming the work as such streetscape dominates the central business district and it is evolving elsewhere, mirroring the expansion of new towns. In turn, another identified cluster, indicating sparse landscapes, decreased, while areas that are considered to be in the most visually pleasant cluster, increased. For the first time, this study demonstrates a novel method to understand the urban visual structure and analyse its spatio-temporal evolution, which could support future planning decision-making and urban landscape betterment."}
{"Paper Title": "A review on artificial intelligence applications for facades", "Abstract": "This review applies a transformer-based topic model to reveal trends and relationships in Artificial Intelligence (AI)-driven facade research, with a focus on architectural, environmental, and structural aspects. AI methods reviewed include Machine Learning (ML), Deep Learning (DL), and Computer Vision (CV). Overall, a significantly growing interest in applying AI methods can be observed across all research areas. However, noticeable differences exist between the three topics. While CV and DL techniques are applied to image data in research on the architectural design of facades, research on environmental aspects of facades often uses numerical data with relatively small datasets and classical ML models. Research on facade structure also tends to use image data but also incorporates numerical performance prediction. A major limitation remains a lack of generalizability, which could be addressed by more comprehensive datasets and novel DL techniques. These include concepts such as Physics-Informed Neural Networks, where domain knowledge is integrated into hybrid data-driven models, and multi-modal diffusion models, which offer generative modeling capabilities to support inverse and forward design tasks. The trends and directions outlined in this review suggest that AI will continue to advance facade research and, in line with other domains, has the potential to achieve a level of maturity suitable for adoption beyond academia and into practice."}
{"Paper Title": "Fine-grained building function recognition with street-view images and GIS map data via geometry-aware semi-supervised learning", "Abstract": "The diversity of building functions is vital for urban planning and optimizing infrastructure and services. Street-view images offer rich exterior details, aiding in function recognition. However, street-view building function annotations are limited and challenging to obtain. In this work, we propose a geometry-aware semi-supervised method for fine-grained building function recognition, which effectively uses multi-source geoinformation data to achieve accurate function recognition in both single-city and cross-city scenarios. We restructured the semi-supervised method based on the Teacher–Student architecture into three stages, which involve pre-training for building facade recognition, building function annotation generation, and building function recognition. In the first stage, to enable semi-supervised training with limited annotations, we employ a semi-supervised object detection model, which trains on both labeled samples and a large amount of unlabeled data simultaneously, achieving building facade detection. In the second stage, to further optimize the pseudo-labels, we effectively utilize the geometric spatial relationships between GIS map data and panoramic street-view images, integrating the building function information with facade detection results. We ultimately achieve fine-grained building function recognition in both single-city and cross-city scenarios by combining the coarse annotations and labeled data in the final stage. We conduct extensive comparative experiments on four datasets, which include OmniCity, Madrid, Los Angeles, and Boston, to evaluate the performance of our method in both single-city (OmniCity & Madrid) and cross-city (OmniCity - Los Angeles & OmniCity - Boston) scenarios. The experimental results show that, compared to advanced recognition methods, our method improves mAP by at least 4.8% and 4.3% for OmniCity and Madrid, respectively, while also effectively handling class imbalance. Furthermore, our method performs well in the cross-categorization system experiments for Los Angeles and Boston, highlighting its strong potential for cross-city tasks. This study offers a new solution for large-scale and multi-city applications by efficiently utilizing multi-source geoinformation data, enhancing urban information acquisition efficiency, and assisting in rational resource allocation."}
{"Paper Title": "Developing WasteSAM: A novel approach for accurate construction waste image segmentation to facilitate efficient recycling", "Abstract": "The escalating volume of construction activities and resultant waste generation underscores the imperative for developing sophisticated segmentation models to facilitate efficient sorting and recycling processes. This study introduces WasteSAM, an enhanced iteration of the segment anything model (SAM), specifically tailored to address the intricate complexities inherent in construction waste imagery. Drawing upon a comprehensive dataset comprising over 15,000 masks representing five distinct categories of construction materials, WasteSAM exhibits notably superior segmentation capabilities. Quantitative analysis demonstrates significant performance improvements, with WasteSAM outperforming the original SAM model by an average of 23.9% in dice similarity coefficient and 30.0% in normalized surface distance metrics. The integration of stereo-image techniques in refining the training dataset has facilitated WasteSAM in more accurately discerning the three-dimensional structure of waste materials, thereby augmenting the precision of waste classification. Noteworthy is the model’s adeptness in handling intricate textures and patterns across diverse imaging modalities, including varying lighting conditions and complex object interactions. While showing promising results, this study also highlights the need for high-quality, diverse datasets that reflect real-world construction site complexities, rather than merely larger datasets. © The Author(s) 2024"}
{"Paper Title": "Enhancing building performance evaluation through Google street View: A multimodal transfer learning framework", "Abstract": "Building energy efficiency is critical for carbon neutrality, yet rapid, large-scale performance assessment remains challenging. This study introduces a three-stage multimodal framework combining Google Street View (GSV) imagery and GIS data to predict building-level Energy Performance Certificates (EPC), wall ratings, and Energy Use Intensity (EUI). First, facade extraction optimizes GSV camera viewpoints using GIS coordinates, segmenting key architectural features. Second, a deep learning model classifies wall performance (star ratings: very poor–very good) and EPC grades (A–G), incorporating shooting distance/angle analysis to enhance feature discrimination. Third, a pretrained energy model integrates building attributes with deep learning outputs, validated through transfer learning on 1 % local samples (e.g., 120 buildings) across UK cities. The framework achieves 84 % EPC accuracy and 76 % wall rating precision, with Grad-CAM interpretability identifying critical facade features—surface degradation, solar panels, and material patterns. Terraced houses (<7.95 m height) yield highest accuracy when facades occupy > 25 % of images, reducing regional EUI errors (CVRMSE) by 48–52 % versus conventional methods. Transfer learning adapts models to median-scale Middle Super Output Area (MSOA) blocks, outperforming in pre-1980 structures but facing limitations in urban high-rises due to occlusions. This scalable approach enables cost-effective retrofit prioritization and policy-driven decarbonization using widely accessible visual data."}
{"Paper Title": "OpenFACADES: An open framework for architectural caption and attribute data enrichment via street view imagery", "Abstract": "Building properties, such as height, usage, and material, play a crucial role in spatial data infrastructures, supporting various urban applications. Despite their importance, comprehensive building attribute data remain scarce in many urban areas. Recent advances have enabled the extraction of objective building attributes using remote sensing and street-level imagery. However, establishing a pipeline that integrates diverse open datasets, acquires holistic building imagery, and infers comprehensive building attributes at scale remains a significant challenge. Among the first, this study bridges the gaps by introducing OpenFACADES, an open framework that leverages multimodal crowdsourced data to enrich building profiles with both objective attributes and semantic descriptors through multimodal large language models. First, we integrate street-level image metadata from Mapillary with OpenStreetMap geometries via isovist analysis, identifying images that provide suitable vantage points for observing target buildings. Second, we automate the detection of building facades in panoramic imagery and tailor a reprojection approach to convert objects into holistic perspective views that approximate real-world observation. Third, we introduce an innovative approach that harnesses and investigates the capabilities of open-source large vision-language models (VLMs) for multi-attribute prediction and open-vocabulary captioning in building-level analytics, leveraging a globally sourced dataset of 31,180 labeled images from seven cities. Evaluation shows that fine-tuned VLM excel in multi-attribute inference, outperforming single-attribute computer vision models and zero-shot ChatGPT-4o. Further experiments confirm its superior generalization and robustness across culturally distinct region and varying image conditions. Finally, the model is applied for large-scale building annotation, generating a dataset of 1.2 million images for half a million buildings. This open-source framework enhances the scope, adaptability, and granularity of building-level assessments, enabling more fine-grained and interpretable insights into the built environment. Our dataset and code are available openly at: https://github.com/seshing/OpenFACADES. © 2025 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)"}
{"Paper Title": "Computer vision-based approach for autonomous estimation of building envelope material stock", "Abstract": "Building envelope components, such as façades and roofs, typically have shorter life spans than structural elements and experience more frequent replacement rates. These components present critical opportunities for promoting circular economy (CE) strategies, particularly reuse, recycling, and material recovery, while minimising down-cycling and landfill. However, accurate and scalable building stock estimation at the elemental level remains a challenge due to the significant time and cost involved in conventional data collection methods. To address this gap, this study employs computer vision-based approaches to autonomously estimate building envelope material stock, focusing on façades and roofs within the Southport North Statistical Area Level 2 (SA2) region of Queensland, Australia. For façade classification, a ResNet50 model with an 80 % accuracy rate was deployed. Roof material and roof type, instance segmentation was undertaken using the YOLOv8 model, which achieved approximately 70 % accuracy. High-resolution street-level and aerial imagery supported the classification and segmentation tasks. Where image data were unavailable, weighted material intensity values were applied to supplement stock estimation. Unlike prior studies that relied on aggregated data, this study introduces a point-level spatial analysis framework to estimate stock at the individual building level. This granularity supports CE applications, such as material recovery planning and facility locating strategies. The integrated approach demonstrates a scalable pathway for autonomous, bottom-up envelope material stock estimation using computer vision, offering a significant advancement in closing the information gap for CE planning and applications."}
{"Paper Title": "Towards a ‘resource cadastre’ for a circular economy – Urban-scale building material detection using street view imagery and computer vision", "Abstract": "The lack of data on existing buildings hinders efforts towards repair, reuse, and recycling of materials, which are crucial for mitigating the climate crisis. Manual acquisition of building data is complex and time-consuming, but combining street-level imagery with computer vision could significantly scale-up building materials documentation. We formulate the problem of building facade material detection as a multi-label classification task and present a method using GIS and street view imagery with just a few hundred annotated samples and a fine-tuned image classification model. Our method shows strong performance with macro-averaged F1 scores of 0.91 for Tokyo, 0.91 for NYC, 0.96 for Zurich, and 0.93 for the merged dataset. By utilizing open-access and non-proprietary data, our method can be scaled-up step by step to a global level. We make our in the wild dataset publicly available as the Urban Resource Cadastre Repository to encourage future work on automatic building material detection."}
{"Paper Title": "Synergizing machine learning and experimental analysis to predict post-heating compressive strength in waste concrete", "Abstract": "In the current study, the impact of utilizing granite and marble construction waste powders as replacements (1%–9%) for cement on concrete compressive strength was investigated. In the second stage of the experimental program, combined mixtures were designed to evaluate their response to high temperatures using various machine learning (ML) techniques. Models employing water cycle algorithm (WCA) and genetic algorithms (GA) were developed based on 288 experimental results, featuring input variables such as temperature, exposure time, waste powder type, and cement replacement ratio, with residual compressive strength (RCS) as the sole output. Artificial neural networks (ANN), fuzzy logic (FL), and multiple linear regression (MLR) models were also developed for comparison. Optimal performance, with a 22% increase in compressive strength at 28 days, was observed by replacing 9% of cement with waste granite powder (WGP). At high temperatures, the best performance occurred with 9% WGP + 5% waste marble powder (WMP), resulting in a 59.6% increase in RCS value after exposure to 800°C for 2 h. The predictive WCA model outperformed GA and MLR, closely aligning with ANN and FL models, with a mean absolute error of 3.96 kg/cm2. Additionally, nonlinear prediction equations of RCS with high regression values were successfully developed using WCA and GA. Furthermore, sensitivity analyses were conducted using the weights of the hidden layers of the idealized neural networks and revealed that the RCS value exhibits high sensitivity to temperature variations. Exposure time had the second-highest impact on RCS value, followed by the WGP ratio, and then the WMP ratio."}
{"Paper Title": "Machine learning-based compressive strength prediction for concrete: An adaptive boosting approach", "Abstract": "In this paper, an intelligent approach based on the machine learning technique is proposed for predicting the compressive strength of concrete. This approach employs the adaptive boosting algorithm to construct a strong learner by integrating several weak learners, which can find the mapping between the input data and output data. The weak learner whose predicting error is small will have a larger weight in the entire system, thus the overall accuracy of the strong learner will be enhanced. A total of 1030 sets of concrete compressive strength tests is collected to train and test the learners, in which the concrete mixture components (e.g., coarse/fine aggregates, cement, water, additive, etc.) and the curing time are set as the input data while the compressive strength value is set as the output data. The proposed approach is validated through a 10-fold cross validation method, and reaches an average accuracy of over 95% in sense of determination coefficient. In addition, a new dataset of 103 samples for concrete compressive strength is also adopted to demonstrate the generalization power of the proposed mode. The proposed approach is also compared to some other individual machine learning techniques that are already applied in this field, e.g., artificial neural network (ANN) and support vector machine (SVM), and shows superior advantages over these methods. Finally, the influence of some key factors in the adaptive boosting approach is also investigated, e.g., the amount of training data, the choice of weak learner, and the influence of the sensitivity and number of the input parameters. It is shown that using 80% of the total data for training can obtain acceptable prediction results and decision tree is the best choice for the weak learner in the boosting framework. Also, the importances of different input variables are obtained based on the sensitivity analysis results. © 2019 Elsevier Ltd"}
{"Paper Title": "Comparing the performance of machine learning models for predicting the compressive strength of concrete", "Abstract": "This work aimed to investigate and compare the performance of different machine learning models in predicting the compressive strength of concrete using a data set of 1234 compressive strength values. The predictive variables were selected based on their relevance using the SelectKBest method, resulting in an analysis of eight and six predictive variables. The evaluation was conducted through linear correlation studies via simple linear regression and non-linear correlation studies using support vector regression (SVR), random forest (RF), gradient boosting (GB), and artificial neural networks (ANN). The results showed a coefficient of determination (R2) = 0.897 and a root mean square error (RMSE) = 6.535 MPa for SVR, R2 = 0.885 and RMSE = 5.437 MPa for GB, R2 = 0.868 and RMSE = 5.859 MPa for GB and R2 = 0.894 and RMSE = 5.192 MPa for ANN, all for test set and eight predictor variables. The comparison between the machine learning methods revealed significant differences. For instance, ANN stood out with a higher R2 value, demonstrating its remarkable ability to explain the variability in the data. ANN also showed the lowest RMSE value, indicating notable accuracy in the predictions. Although ANN has demonstrated higher performance, GB shows a closer performance, which no differences from a practical application. The choice between these approaches depends on considerations regarding the balance between explainability and accuracy. While GB provides a more in-depth understanding of the relationship between variables, ANN stands out for the accuracy of its predictions."}
{"Paper Title": "Artificial intelligence-based ensemble models with GUI for predicting the compressive strength of waste glass concrete", "Abstract": "The sustainable utilization of post-consumer waste glass in concrete has emerged as a promising approach to reduce cement consumption, mitigate landfill disposal, and enhance material performance. However, most previous predictive studies have relied on limited datasets, excluded chemical composition effects, or used single machine-learning algorithms, leading to restricted generalization. This study evaluates and develops artificial intelligence-based ensemble learning models to predict the compressive strength of concrete incorporating waste glass powder (WGP) as a partial cement replacement. A dataset of 337 experimental results was compiled from the literature published between 2007 and 2024, including eleven key input variables such as WGP size and replacement level, water-to-cement ratio (W/C), aggregate properties, curing age, and chemical composition of WGP (SiO2, CaO, NaO). Five advanced ensemble algorithms — Gradient Boosting Regressor, Extreme Gradient Boosting Regressor, LightGBM Regressor, CatBoost Regressor, and Histogram-based Gradient Boosting regressor — were trained and optimized using Bayesian hyperparameter tuning and validated with 10-fold cross-validation. Performance was assessed using R, RMSE, MSE, MAE, and MAPE metrics. All models demonstrated excellent predictive ability (R  0.94), with CatBoost achieving the highest testing accuracy (R = 0.96, RMSE = 2.34 MPa, MAE = 1.63 MPa). Feature importance and SHAP analysis revealed curing time and W/C as the most influential parameters, followed by aggregate content and WGP replacement level. Parametric studies confirmed the expected concrete behavior, with strength gains over curing time and reductions at high WGP replacement and W/C. A graphical user interface (GUI) was developed using the CatBoost model, enabling the practical prediction of compressive strength for various mix designs. The integration of chemical composition-based modeling, ensemble learning optimization, and GUI deployment establishes a practically oriented framework that advances sustainable concrete design and facilitates its broader adoption within the construction industry."}
